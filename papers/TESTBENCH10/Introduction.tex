\section{Introduction}\label{sec:intro}
The goal of software testing is not to show that a program is fault free, because this is a practical impossibility, but rather to find as many of its faults as possible \cite{Myers}. Even if a program performs each of the behaviours described in its specification correctly, there is no guarantee it will conform to the specification in all of its behaviours. In other words, we cannot be sure a program that behaves correctly on inputs that have been considered will behave correctly on those that have not been. Myers suggests test cases are successful if they cause the software to fail. Under this definition, successful test cases always reveal undesired behaviour in the software, but it is difficult to produce an accurate measure of confidence in the software’s correctness. In order to provide confidence, the software must be executed under typical conditions. Hamlet and Taylor highlight the failure finding nature of partitioning schemes as being inappropriate for confidence testing and point out that random testing is better suited for this task \cite{Hamlet}.

Confidence testing may be performed on a program by comparing its test results against those of other benchmarked programs. Runeson et al explain such benchmarks are typically built around availability and are not necessarily best suited to the specific context of the program under evaluation \cite{Runeson}. Programs included in benchmarks are often too trivial to be relevant to the testing of industrial scale applications and do not take into account differences in the type of defects that may be found or the development process. This paper aims to reduce some of the variation involved in these factors by categorising software into different application areas for testing. With the availability of open source software, it is possible to find examples of industrial scale applications for each test category. The hope is that by tailoring the benchmark to the specific application, a more reliable confidence measure may be achieved for the software under test.
