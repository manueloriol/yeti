\section{Related Work}\label{sec:rw}

With programs becoming increasingly complex, the process of testing 
them has to become smarter and more efficient. Automated random testing
is a technique that is cheap to run and proved to find bugs in Java libraries and 
programs~\cite{Pacheco2005,Csallner2004}, in Haskell 
programs~\cite{Claessen00quickcheck:a}.

YETI is the latest in a serie of recent random testing tools like
JCrasher~\cite{Csallner2004}, Eclat~\cite{Pacheco2005}, Jtest~\cite{Jtest},
Jartege~\cite{Oriat2004}, RUTE-J~\cite{Andrews2006a}, and in particular 
AutoTest~\cite{Ciupa2007,CLOM:08:AARTOO,CPLOM:08:PRTOOS}. YETI is however 
different from these tools in at least three important ways: (1) it is made to 
easily support multiple programming languages, (2) 
it is intended to allow test engineers to modify the parameters of the 
testing during the testing session itself, and (3) it is at least 3 orders 
of magnitude faster than competing tools. 

The first characteristics comes from
the meta-model that YETI uses that is not bound to a specific paradigm.
It also implies that some domain-specific optimizations~\cite{Pacheco2007,Godefroid2005,Chen2004a,Chen2005} will not be possible 
without additional support because YETI does not know values or language-specific
constructs. 

The second point is the truly innovative point. All other approaches
considered the testing tool to be a component that would run by itself without 
further interactions. In our experience the runtime monitoring has become 
the main means of knowing how the testing session evolves and possibly to 
improve it by modifying some parameters. 

The last characteristics 
clearly depends on the reference implementation being in Java and testing Java
programs -- other bindings might exhibit slower performances. It is however 
worth noting that this has a direct impact on the capability for the tool to 
test thoroughly big amount of code in short period of time.
