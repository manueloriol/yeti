\section{Related Work}\label{sec:rw}
Distributing software testing over multiple computers has received very little attention in the research community. Starkloff~\cite{stark} presents the general advantages of parallelizing software testing systems and how to achieve parallelism by distributing execution. 

Lastovetsky and Alexey~\cite{lasto} present a case for testing of a distributed programming system where serial execution of a regression test suite would on the average take at least 90 hours per bug detected, whereas Parallelizing the execution on a number of local UNIX computers resulted in a speed up of up to 7.7 on two 4-processor workstations, which meant the test suite could be run multiple times in a single day.

Further work resulted in tools like Joshua ~\cite{Kap}, and GridUnit~\cite{Duarte1, Duarte2, Duarte3}. 
Joshua uses Jini for distributing the execution of a regression test suite across a number of CPUs and 
writes the results back to a centralized repository, whereas GridUnit employs a computational Grid to speed up the testing process. 
A single master distributes test cases for execution across machines in a Grid and then waits for the results.
Both Joshua and GridUnit extend the JUnit testing framework. Using the same principles, Yao \textit{et al.}~\cite{yao} present the implementation of a grid-based unit testing framework and present some preliminary results based on simulation. 
The framework  differs from Joshua and GridUnit in its support for NUnit and dbUnit apart from JUnit, extending its support for C\# and database-driven projects.

Some of the limitations of such approaches, however, include the requirement that a test case be manually created beforehand, and their execution on either a local LAN or a Grid. A LAN has limited number of machines whereas, in a Grid, nodes might have different computational capacities varying from supercomputers to a low-end personal computer~\cite{yao}. This would seriously impact the performance 
of some test cases and work would have to be assigned according to the workers capacity. 

The only approach that is somewhat similiar to our implementatin for distributing execution is outlined in ~\cite{parveen}, where a prototype distributed execution framework for 
JUnit test cases called HadoopUnit is presented. They also use the MapReduce primitives for distributing test cases. Before execution can begin, an Ant task is run 
to produce input for the map function from uploaded files and stores them in a file to be later read by the Mapper. The Reducer then collects the test case results from each Mapper 
and outputs them to a file on the DFS. A speed of 30x in execution time is reported on a 150-node cluster. 
However, HadoopUnit too only supports execution of JUnit test cases and requires them be created manually beforehand. 

YETI creates test cases on the fly, executes them against the target code and reports bugs. The use of a computational Cloud by YETI resolves the issues outlined above, 
since the test cases are created automatically, each node has the same processing power and new nodes can be added dynamically, if more processing power is required. 



