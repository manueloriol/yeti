\section{Related Work}\label{sec:rw}
Distributing software testing over multiple computers has received very little attention in the research community. Starkloff~\cite{stark} presents the general advantages of parallelizing software testing systems and how to achieve parallelism by distributing execution. 

Lastovetsky and Alexey~\cite{lasto} present a case for testing of a distributed programming system where serial execution of a regression test suite would on the average take at least 90 hours per bug detected, whereas Parallelizing the execution on a number of local UNIX computers resulted in a speed up of up to 7.7 on two 4-processor workstations, which meant the test suite could be run multiple times in a single day.

Further work resulted in tools like Joshua ~\cite{Kap}, and GridUnit~\cite{Duarte1, Duarte2, Duarte3}. 
Joshua uses Jini for distributing the execution of a regression test suite across a number of CPUs and 
writes the results back to a centralized repository, whereas GridUnit employs a computational Grid to speed up the testing process. 
A single master distributes test cases for execution across machines in a Grid and then waits for the results.
Both Joshua and GridUnit extend the JUnit testing framework. Using the same principles, Yao \textit{et al.}~\cite{yao} present the implementation of a grid-based unit testing framework and present some preliminary results based on simulation. 
The framework  differs from Joshua and GridUnit in its support for NUnit and dbUnit apart from JUnit, extending its support for C\# and database-driven projects.

Some of the limitations of such approaches, however, include the requirement that a test case be manually created beforehand, and their execution on either a local LAN or a Grid. A LAN has limited number of machines whereas, in a Grid, nodes might have different computational capacities varying from supercomputers to a low-end personal computer~\cite{yao}. This would seriously impact the performance 
of some test cases and work would have to be assigned according to the workers capacity. 


YETI creates the test cases on the fly, executes them against the target code and reports bugs. The use of a computational Cloud by YETI resolves the issues outlined above, since each node has the same processing power and new nodes can be added dynamically, if more processing power is required. 



